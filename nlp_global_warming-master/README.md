# NLP_Global_Warming

## Table of Contents

- General Info
- Technologies used
- Features
- Setup
- Usage
- Project staus
- Room for improvement

## General Info

The global warming dataset contains three coloumns, tweetid, message and sentiment. The "tweetid" coloumn, is a column of unique intergers belonging
to the tweeps(user) who tweeted. The "message" coloumn contains comments and satements from the tweeps, sharing their thoughts on global warming. The "sentiment" column, contains sentiment ratings of the messages from negative to positive. The main purpose of this project is to anylise the dataset, train models to predict the sentiment of the message/text(NLP) and then build a working application that will used to enter the message/text and predict the sentiment.      

## Technologies used

- VS Code version 1.70
- Jupyter Notebook version 2022.7.1102252217
- Anaconda version 2.1.1


## Features

- Bar graph show sentiment count of the dataset
- Pie chart showing distribution of sentiment
- Wordcloud showing the most used words in a class
- Box plot showing the length of the tweet
s

## Setup

I was required to create a system that predicts the sentiment of a text.

I first had to clean the data and preproces it for machine learning, I then had to explore and anylise the dataset using pandas. I then had to train the model using different algorithms and select the most accurate. I then had to develop a front-end web application to use the system.


## Usage

from analysing the dataset one can have an idea on what people think about global warming and the system can be used to determine the sentiment of a tweet.

## Project staus
Project Completed.

## Room for improvement
The data set was not balanced, synthetic data should have been created to balance out the class. A dictionary should have been used to replace texting-lingo, words such as luv,2moro etc
